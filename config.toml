[general]
# Name given to the embeddings vector collection 
collection_name = "docs"
# Used when generating embeddings with a locally downloaded model, e.g. Hugging Face or Instructor
default_device = "cuda"
# Choose amongst: "chromadb", "redis", "pgvector", "pinecone", "mongodb_atlas", "elasticsearch", "neo4j"
vectordb_provider = "neo4j"
# Choose amongst: "openai", "huggingface", "instructor", "ollama"
embeddings_provider = "instructor"

[docs]
# List of directories where source documents live
source_dirs = ["corpus"]
# File mask, e.g. "**/[!.]*.*" every (non-hidden) doc with any extension 
glob = "**/[!.]*.*"

[splitter]
# Maximum size of document chunks to return
chunk_size = 1000
# Overlap in characters between chunks
chunk_overlap = 20

[search_params]
# Can be "similarity" (default), "similarity_score_threshold", or "mmr" Maximal Marginal Relevance algorithm
# which optimises for BOTH similarity to querystring AND diversity amongst selected documents
algorithm = "similarity"
# Number of documents to retrieve on "similarity" search
k = 4
# Number of docs passed to MMR algorithm
# fetch_k = 20
# Diversity of results returned by MMR (1 for minimum diversity and 0 for maximum)
# lambda_mult = 0.5
# Minimum relevance threshold for "similarity_score_threshold"
# score_threshold = 0.5

[openai]
# Don't write it here, put it in non-versioned secrets.toml
api_key = "API-KEY"
# Don't try to use "gpt-4" unless you've prepaid or are in the premium tier
chat_model = "gpt-3.5-turbo"
# Between 0 and 1, governs the randomness (and thus the creativity) of the responses
temperature = 0.7
# Prompt template fed to the GPT model
prompt_template = """You are an AI assistant that answers questions about our company's policy. 
Use the following pieces of context to answer the question at the end.
If you don't know the answer, just say that you don't know, don't try to make up an answer.
Always say thank you at the end.

{context}

Question: {question}
Helpful, extended answer:"""

[chromadb]
# Root directory to persist the CromaDB SQLite database and other files
persistence_root_dir = "chroma_db"

[redis]
# URL to access the Redis Stack instance
url = "redis://localhost:6379"

[pgvector]
# sqlalchemy-style connection string. Don't write it here, put it in non-versioned secrets.toml
connection_string = "postgresql+psycopg2://vector_user:vector_pass@localhost:5432/vectors"

[pinecone]
# Don't write it here, put it in non-versioned secrets.toml
api_key = "API_KEY"
# Environment name from pinecone.io
environment = "ENVIRONMENT"

[mongodb_atlas]
# Don't write it here, put it in non-versioned secrets.toml
connection_string = "mongodb+srv://username:password@cluster.xxxxxxx.mongodb.net/?retryWrites=true&w=majority"
# DB name
db_name = "vectors"

[elasticsearch]
# Don't write it here, put it in non-versioned secrets.toml
url = "http://elastic:my_secret_pwd@localhost:9200"

[neo4j]
# URL to access the Neo4j instance
url = "neo4j://localhost:7687"
# Don't write it here, put it in non-versioned secrets.toml
username = "USERNAME"
# Don't write it here, put it in non-versioned secrets.toml
password = "PASSWORD"
